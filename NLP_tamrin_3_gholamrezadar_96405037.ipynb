{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_tamrin_3_gholamrezadar_96405037.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMGUk/Us+m0knHi8XjAjJZ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gholamrezadar/Colab-notebooks/blob/main/NLP_tamrin_3_gholamrezadar_96405037.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHN65z7n1t_a"
      },
      "source": [
        "NLP Tamrin 3\n",
        "\n",
        "Gholamrezadar Nov 2020\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Omuie6S2707"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvRPEvKatoYl"
      },
      "source": [
        "!pip install hazm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6tbO1EVXN03"
      },
      "source": [
        "!wget https://github.com/sobhe/hazm/releases/download/v0.5/resources-0.5.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PXDcMleXdhx"
      },
      "source": [
        "!unzip \"/content/resources-0.5.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_lATtvD0JyX"
      },
      "source": [
        "import hazm\n",
        "import nltk\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkjZl2pt117X"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAnN-2hgkcbg"
      },
      "source": [
        "english_doc = \"\"\"A regular expression is a form of advanced searching that looks for specific patterns, as opposed to certain terms and phrases. With RegEx you can use pattern matching to search for particular strings of characters rather than constructing multiple, literal search queries. <b>RegEx</b> uses metacharacters in conjunction with a search engine to retrieve specific patterns. Metacharacters are the building blocks of regular expressions. For example, “\\d” in a regular expression is a metacharacter that represents a digit character, but “d” stands for the literal character, “d.” You can use regular expressions to search for social security numbers, patent numbers, URLs, email addresses, Bates numbers, and other strings that follow a specific pattern. RegEx can help you in cases where you need to find different numbers that contain the same pattern, for example, the following serial numbers: XFRD-8324-ERWH-3231 , GHSR-3413-KBKV-8173.\n",
        "So we are goning to have discussion about it. My number is: 09101007567. but it's <b> better </b> to save it as +989101007567. 9111231234 and 0914513 are invalid. Ask your question from info_test@unkown.ir or <b> info@unkown.com </b> or test_#23@unkown.com\"\"\"\n",
        "\n",
        "persian_doc = \"\"\"پیر مردی هر روز تو محله می دید پسر کی با کفش های پاره و پای برهنه با توپ پلاستیکی فوتبال بازی می کند، روزی رفت ی کتانی نو خرید و اومد و به پسرک گفت بیا این کفشا رو بپوش…پسرک کفشا رو پوشید و خوشحال رو به پیر مرد کرد و گفت: شما خدایید؟! پیر مرد لبش را گزید و گفت نه! پسرک گفت پس دوست خدایی، چون من دیشب فقط به خدا گفتم كه کفش ندارم…\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKJziKlc35Pd"
      },
      "source": [
        "def print_table(array,m=6):\n",
        "  lens = map(lambda a: len(str(a)), array)\n",
        "  max_len = max(list(lens))\n",
        "  n = len(array)\n",
        "  for i in range(0,n,m):\n",
        "    for j in array[i:i+m]:\n",
        "      print(str(j).center(max_len,\" \"),end=' | ')\n",
        "    print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1teHTjNSu2t0"
      },
      "source": [
        "## English Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrmtLG5oulfr"
      },
      "source": [
        "### #1. Finding all tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4pDQd0duxyY",
        "outputId": "a5314413-d74e-4957-d4f3-53f3226f177d"
      },
      "source": [
        "result = re.findall(r'\\w+|<[^<>]+>|<\\/[^<>]+>', english_doc)\n",
        "print_table(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      A        |    regular     |   expression   |       is       |       a        |      form      | \n",
            "      of       |    advanced    |   searching    |      that      |     looks      |      for       | \n",
            "   specific    |    patterns    |       as       |    opposed     |       to       |    certain     | \n",
            "    terms      |      and       |    phrases     |      With      |     RegEx      |      you       | \n",
            "     can       |      use       |    pattern     |    matching    |       to       |     search     | \n",
            "     for       |   particular   |    strings     |       of       |   characters   |     rather     | \n",
            "     than      |  constructing  |    multiple    |    literal     |     search     |    queries     | \n",
            "     <b>       |     RegEx      |      </b>      |      uses      | metacharacters |       in       | \n",
            " conjunction   |      with      |       a        |     search     |     engine     |       to       | \n",
            "   retrieve    |    specific    |    patterns    | Metacharacters |      are       |      the       | \n",
            "   building    |     blocks     |       of       |    regular     |  expressions   |      For       | \n",
            "   example     |       d        |       in       |       a        |    regular     |   expression   | \n",
            "      is       |       a        | metacharacter  |      that      |   represents   |       a        | \n",
            "    digit      |   character    |      but       |       d        |     stands     |      for       | \n",
            "     the       |    literal     |   character    |       d        |      You       |      can       | \n",
            "     use       |    regular     |  expressions   |       to       |     search     |      for       | \n",
            "    social     |    security    |    numbers     |     patent     |    numbers     |      URLs      | \n",
            "    email      |   addresses    |     Bates      |    numbers     |      and       |     other      | \n",
            "   strings     |      that      |     follow     |       a        |    specific    |    pattern     | \n",
            "    RegEx      |      can       |      help      |      you       |       in       |     cases      | \n",
            "    where      |      you       |      need      |       to       |      find      |   different    | \n",
            "   numbers     |      that      |    contain     |      the       |      same      |    pattern     | \n",
            "     for       |    example     |      the       |   following    |     serial     |    numbers     | \n",
            "     XFRD      |      8324      |      ERWH      |      3231      |      GHSR      |      3413      | \n",
            "     KBKV      |      8173      |       So       |       we       |      are       |     goning     | \n",
            "      to       |      have      |   discussion   |     about      |       it       |       My       | \n",
            "    number     |       is       |  09101007567   |      but       |       it       |       s        | \n",
            "     <b>       |     better     |      </b>      |       to       |      save      |       it       | \n",
            "      as       |  989101007567  |   9111231234   |      and       |    0914513     |      are       | \n",
            "   invalid     |      Ask       |      your      |    question    |      from      |   info_test    | \n",
            "    unkown     |       ir       |       or       |      <b>       |      info      |     unkown     | \n",
            "     com       |      </b>      |       or       |     test_      |       23       |     unkown     | \n",
            "     com       | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pFCjTbrABRZ"
      },
      "source": [
        "### #2. Finding all numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y72PV_shAFUk",
        "outputId": "d7c2c562-cae1-424d-b4f8-0975b49b79cf"
      },
      "source": [
        "result = re.findall(r'\\d+', english_doc)\n",
        "print_table(result,m=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    8324     |     3231     |     3413     |     8173     | \n",
            "09101007567  | 989101007567 |  9111231234  |   0914513    | \n",
            "     23      | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeKMfjZ0A1j8"
      },
      "source": [
        "### #3. find phone numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI-Ovo_PA4d5",
        "outputId": "9ece5164-aecf-4427-d1b2-33ed8aa5a454"
      },
      "source": [
        "result = re.findall(r'09\\d{9}|\\+9891\\d{8}', english_doc)\n",
        "print_table(result,m=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 09101007567  | +989101007567 | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pl8MRlkDV6o"
      },
      "source": [
        "### #4. Finding XXXX-XXXX-XXXX-XXXX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpt3vICnDWeJ",
        "outputId": "c52360f3-42a2-440b-f798-8877831eae5f"
      },
      "source": [
        "result = re.findall(r'[a-zA-Z]{4}-\\d{4}-[a-zA-Z]{4}-\\d{4}', english_doc)\n",
        "print_table(result,m=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XFRD-8324-ERWH-3231 | GHSR-3413-KBKV-8173 | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVcdyBO5EoW2"
      },
      "source": [
        "### #5. Finding emails"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnzdqakkEojx",
        "outputId": "5ae57d95-1400-4895-eab5-f45f65bb66d2"
      },
      "source": [
        "result = re.findall(r'(\\S+@\\w+(\\.[a-zA-Z]{2,})+)', english_doc)\n",
        "print_table(list(map(lambda x : x[0], result)),m=4)\n",
        "\n",
        "# testing subdomains and 1 length domains\n",
        "print(\"\\nTesting subdomains and 1 length domains\")\n",
        "\n",
        "emails = \"gholamrezadar@uk.ac.ir, ghd@aasd.a, hsgdg@google.gov.ir\"\n",
        "result = re.findall(r'(\\S+@\\w+(\\.[a-zA-Z]{2,})+)', emails)\n",
        "print_table(list(map(lambda x : x[0], result)),m=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "info_test@unkown.ir |   info@unkown.com   | test_#23@unkown.com | \n",
            "\n",
            "Testing subdomains and 1 length domains\n",
            "gholamrezadar@uk.ac.ir |  hsgdg@google.gov.ir   | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtNlizstKHDW"
      },
      "source": [
        "### #6. Finding Bold Texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBUlB-uzKHWi",
        "outputId": "31dc74ca-2a8d-4de0-872e-5545d797d482"
      },
      "source": [
        "result = re.findall(r'<b>([^<>]+)<\\/b>', english_doc)\n",
        "print_table(result,m=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      RegEx       |       better      |  info@unkown.com  | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kod-93yAK0Ii"
      },
      "source": [
        "### #7. Finding Upper-case Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuEnLCf4LRBo",
        "outputId": "cbde3767-f759-4241-e858-0d316e064427"
      },
      "source": [
        "result = re.findall(r'\\b[A-Z]\\w*\\b', english_doc)\n",
        "print_table(result,m=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      A        |      With      |     RegEx      |     RegEx      | \n",
            "Metacharacters |      For       |      You       |      URLs      | \n",
            "    Bates      |     RegEx      |      XFRD      |      ERWH      | \n",
            "     GHSR      |      KBKV      |       So       |       My       | \n",
            "     Ask       | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os0EzeAJMTKx"
      },
      "source": [
        "### #8. Finding Frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PHytEwQMTiB",
        "outputId": "33d7729d-ca1f-4241-e75b-b257255d2f50"
      },
      "source": [
        "result = re.findall(r'\\w+|<[^<>]+>|<\\/[^<>]+>', english_doc)\n",
        "fdist = nltk.FreqDist(result)\n",
        "\n",
        "# Output top 50 words\n",
        "output = []\n",
        "for word, frequency in fdist.most_common(50):\n",
        "  output.append(word)\n",
        "  output.append(str(frequency))\n",
        "\n",
        "print_table(output,m=2)\n",
        "print(\".\".center(32))\n",
        "print(\".\".center(32))\n",
        "print(\".\".center(32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     to     |      7      | \n",
            "     a      |      6      | \n",
            "    for     |      5      | \n",
            "  numbers   |      5      | \n",
            "  regular   |      4      | \n",
            "    that    |      4      | \n",
            "   search   |      4      | \n",
            "    the     |      4      | \n",
            "     is     |      3      | \n",
            "     of     |      3      | \n",
            "  specific  |      3      | \n",
            "    and     |      3      | \n",
            "   RegEx    |      3      | \n",
            "    you     |      3      | \n",
            "    can     |      3      | \n",
            "  pattern   |      3      | \n",
            "    <b>     |      3      | \n",
            "    </b>    |      3      | \n",
            "     in     |      3      | \n",
            "    are     |      3      | \n",
            "     d      |      3      | \n",
            "     it     |      3      | \n",
            "   unkown   |      3      | \n",
            " expression |      2      | \n",
            "  patterns  |      2      | \n",
            "     as     |      2      | \n",
            "    use     |      2      | \n",
            "  strings   |      2      | \n",
            "  literal   |      2      | \n",
            "expressions |      2      | \n",
            "  example   |      2      | \n",
            " character  |      2      | \n",
            "    but     |      2      | \n",
            "     or     |      2      | \n",
            "    com     |      2      | \n",
            "     A      |      1      | \n",
            "    form    |      1      | \n",
            "  advanced  |      1      | \n",
            " searching  |      1      | \n",
            "   looks    |      1      | \n",
            "  opposed   |      1      | \n",
            "  certain   |      1      | \n",
            "   terms    |      1      | \n",
            "  phrases   |      1      | \n",
            "    With    |      1      | \n",
            "  matching  |      1      | \n",
            " particular |      1      | \n",
            " characters |      1      | \n",
            "   rather   |      1      | \n",
            "    than    |      1      | \n",
            "               .                \n",
            "               .                \n",
            "               .                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ppXtoEHRNQL"
      },
      "source": [
        "## Persian Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfywtrxXP8lV"
      },
      "source": [
        "### #9. Normalizing Text\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gif_S6QZQAZU",
        "outputId": "b20aae5f-f296-4c57-c11a-073147ff0178"
      },
      "source": [
        "normalizer = hazm.Normalizer()\n",
        "print(\"Normalized Persian Text : \")\n",
        "print(normalizer.normalize(persian_doc))\n",
        "persian_doc = normalizer.normalize(persian_doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized Persian Text : \n",
            "پیر مردی هر روز تو محله می‌دید پسر کی با کفش‌های پاره و پای برهنه با توپ پلاستیکی فوتبال بازی می‌کند، روزی رفت ی کتانی نو خرید و اومد و به پسرک گفت بیا این کفشا رو بپوش…پسرک کفشا رو پوشید و خوشحال رو به پیر مرد کرد و گفت: شما خدایید؟! پیر مرد لبش را گزید و گفت نه! پسرک گفت پس دوست خدایی، چون من دیشب فقط به خدا گفتم که کفش ندارم…\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVEozqyoQBAB"
      },
      "source": [
        "### #10. Finding sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMDK7ooaQFNB",
        "outputId": "10396588-4896-4732-a609-69ddf1ffbac9"
      },
      "source": [
        "result = hazm.sent_tokenize(persian_doc)\n",
        "_ = [print(i+1,\"-\",sentence) for i,sentence in enumerate(result)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 - پیر مردی هر روز تو محله می‌دید پسر کی با کفش‌های پاره و پای برهنه با توپ پلاستیکی فوتبال بازی می‌کند، روزی رفت ی کتانی نو خرید و اومد و به پسرک گفت بیا این کفشا رو بپوش…پسرک کفشا رو پوشید و خوشحال رو به پیر مرد کرد و گفت: شما خدایید؟!\n",
            "2 - پیر مرد لبش را گزید و گفت نه!\n",
            "3 - پسرک گفت پس دوست خدایی، چون من دیشب فقط به خدا گفتم که کفش ندارم…\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqrlxn4KQFf9"
      },
      "source": [
        "### #11. Finding words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITfv4qQkQFzb",
        "outputId": "5114532a-1649-470a-f80c-6c1e81ba8eb4"
      },
      "source": [
        "result = hazm.word_tokenize(persian_doc)\n",
        "_ = [print(i+1,\"-\",word) for i,word in enumerate(result)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 - پیر\n",
            "2 - مردی\n",
            "3 - هر\n",
            "4 - روز\n",
            "5 - تو\n",
            "6 - محله\n",
            "7 - می‌دید\n",
            "8 - پسر\n",
            "9 - کی\n",
            "10 - با\n",
            "11 - کفش‌های\n",
            "12 - پاره\n",
            "13 - و\n",
            "14 - پای\n",
            "15 - برهنه\n",
            "16 - با\n",
            "17 - توپ\n",
            "18 - پلاستیکی\n",
            "19 - فوتبال\n",
            "20 - بازی\n",
            "21 - می‌کند\n",
            "22 - ،\n",
            "23 - روزی\n",
            "24 - رفت\n",
            "25 - ی\n",
            "26 - کتانی\n",
            "27 - نو\n",
            "28 - خرید\n",
            "29 - و\n",
            "30 - اومد\n",
            "31 - و\n",
            "32 - به\n",
            "33 - پسرک\n",
            "34 - گفت\n",
            "35 - بیا\n",
            "36 - این\n",
            "37 - کفشا\n",
            "38 - رو\n",
            "39 - بپوش…پسرک\n",
            "40 - کفشا\n",
            "41 - رو\n",
            "42 - پوشید\n",
            "43 - و\n",
            "44 - خوشحال\n",
            "45 - رو\n",
            "46 - به\n",
            "47 - پیر\n",
            "48 - مرد\n",
            "49 - کرد\n",
            "50 - و\n",
            "51 - گفت\n",
            "52 - :\n",
            "53 - شما\n",
            "54 - خدایید\n",
            "55 - ؟!\n",
            "56 - پیر\n",
            "57 - مرد\n",
            "58 - لبش\n",
            "59 - را\n",
            "60 - گزید\n",
            "61 - و\n",
            "62 - گفت\n",
            "63 - نه\n",
            "64 - !\n",
            "65 - پسرک\n",
            "66 - گفت\n",
            "67 - پس\n",
            "68 - دوست\n",
            "69 - خدایی\n",
            "70 - ،\n",
            "71 - چون\n",
            "72 - من\n",
            "73 - دیشب\n",
            "74 - فقط\n",
            "75 - به\n",
            "76 - خدا\n",
            "77 - گفتم\n",
            "78 - که\n",
            "79 - کفش\n",
            "80 - ندارم…\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19j2ZcyYQLgX"
      },
      "source": [
        "### #12. Lemmatization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXepz_CtQLvB",
        "outputId": "f92fe286-68df-4f9c-c269-786d89270ae8"
      },
      "source": [
        "# extracting words\n",
        "words = hazm.word_tokenize(persian_doc)\n",
        "\n",
        "# finding verbs\n",
        "model = \"/content/postagger.model\"\n",
        "tagger = hazm.POSTagger(model=model)\n",
        "tagged = tagger.tag(words)\n",
        "verbs = list(filter(lambda x: x[1] == \"V\", tagged))\n",
        "verbs = list(map(lambda x: x[0], verbs))\n",
        "\n",
        "# Lemmatizing\n",
        "lemmatizer = hazm.Lemmatizer()\n",
        "for i,word in enumerate(verbs):\n",
        "  print(i+1,\"-\",lemmatizer.lemmatize(word),\"<-\",word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 - دید#بین <- می‌دید\n",
            "2 - کرد#کن <- می‌کند\n",
            "3 - رفت#رو <- رفت\n",
            "4 - خرید <- خرید\n",
            "5 - اومد <- اومد\n",
            "6 - گفت#گو <- گفت\n",
            "7 - آمد#آ <- بیا\n",
            "8 - پوشید#پوش <- پوشید\n",
            "9 - کرد#کن <- کرد\n",
            "10 - گفت#گو <- گفت\n",
            "11 - خدایید <- خدایید\n",
            "12 - گزید <- گزید\n",
            "13 - گفت#گو <- گفت\n",
            "14 - گفت#گو <- گفت\n",
            "15 - گفت#گو <- گفتم\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}